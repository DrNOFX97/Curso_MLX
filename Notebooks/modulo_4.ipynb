{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√≥dulo 4: T√©cnicas Avan√ßadas de Otimiza√ß√£o\n",
    "\n",
    "### 4.1 Quantiza√ß√£o de Modelos\n",
    "\n",
    "#### O que √© Quantiza√ß√£o?\n",
    "\n",
    "**Quantiza√ß√£o** = Reduzir a precis√£o dos n√∫meros no modelo para usar menos mem√≥ria.\n",
    "\n",
    "**Tipos de n√∫meros em deep learning:**\n",
    "```\n",
    "FP32 (Float32):     4 bytes  ‚Üê Padr√£o\n",
    "FP16 (Float16):     2 bytes  ‚Üê Mixed precision\n",
    "INT8 (Integer 8):   1 byte   ‚Üê Quantiza√ß√£o\n",
    "INT4 (Integer 4):   0.5 byte ‚Üê Quantiza√ß√£o extrema\n",
    "```\n",
    "\n",
    "**Economia de Mem√≥ria:**\n",
    "- Modelo de 1GB em FP32 ‚Üí 250MB em INT8 (75% redu√ß√£o!)\n",
    "- Modelo de 1GB em FP32 ‚Üí 125MB em INT4 (87.5% redu√ß√£o!)\n",
    "\n",
    "**Trade-off:**\n",
    "- ‚úÖ Muito menos mem√≥ria\n",
    "- ‚úÖ Infer√™ncia mais r√°pida\n",
    "- ‚ö†Ô∏è Pequena perda de precis√£o (1-3% tipicamente)\n",
    "\n",
    "#### Post-Training Quantization (PTQ)\n",
    "\n",
    "Quantiza um modelo **j√° treinado** - mais simples e r√°pido!\n",
    "\n",
    "**TensorFlow Lite (excelente para M1):**\n",
    "\n",
    "```python\n",
    "# quantizacao_tensorflow.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def quantizar_modelo_int8(modelo_path, dados_calibracao):\n",
    "    \"\"\"\n",
    "    Quantiza modelo para INT8 usando TensorFlow Lite\n",
    "    Ideal para deployment no M1\n",
    "    \"\"\"\n",
    "    # Carregar modelo\n",
    "    model = keras.models.load_model(modelo_path)\n",
    "    \n",
    "    # Converter para TFLite com quantiza√ß√£o INT8\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # Configurar quantiza√ß√£o completa INT8\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.int8]\n",
    "    \n",
    "    # Dataset representativo para calibra√ß√£o\n",
    "    def representative_dataset():\n",
    "        for data in dados_calibracao:\n",
    "            yield [data.astype(np.float32)]\n",
    "    \n",
    "    converter.representative_dataset = representative_dataset\n",
    "    \n",
    "    # Quantizar!\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Guardar modelo quantizado\n",
    "    with open('modelo_int8.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    # Comparar tamanhos\n",
    "    tamanho_original = os.path.getsize(modelo_path) / (1024**2)\n",
    "    tamanho_quantizado = len(tflite_model) / (1024**2)\n",
    "    reducao = (1 - tamanho_quantizado/tamanho_original) * 100\n",
    "    \n",
    "    print(f\"‚úì Modelo quantizado com sucesso!\")\n",
    "    print(f\"  Original:    {tamanho_original:.2f} MB\")\n",
    "    print(f\"  Quantizado:  {tamanho_quantizado:.2f} MB\")\n",
    "    print(f\"  Redu√ß√£o:     {reducao:.1f}%\")\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "# Exemplo de uso\n",
    "# Preparar dados de calibra√ß√£o (amostra do dataset de treino)\n",
    "x_train_sample = x_train[:1000]  # 1000 amostras\n",
    "\n",
    "# Quantizar\n",
    "modelo_quantizado = quantizar_modelo_int8('modelo_final.keras', x_train_sample)\n",
    "```\n",
    "\n",
    "**Infer√™ncia com modelo quantizado:**\n",
    "\n",
    "```python\n",
    "# inferencia_quantizada.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def inferencia_tflite(modelo_path, input_data):\n",
    "    \"\"\"\n",
    "    Executa infer√™ncia com modelo TFLite quantizado\n",
    "    \"\"\"\n",
    "    # Carregar interpretador TFLite\n",
    "    interpreter = tf.lite.Interpreter(model_path=modelo_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Obter detalhes de input/output\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Preparar input\n",
    "    input_data = input_data.astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Executar\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Obter resultado\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "# Uso\n",
    "predictions = inferencia_tflite('modelo_int8.tflite', test_images)\n",
    "```\n",
    "**PyTorch - Quantiza√ß√£o Din√¢mica:**\n",
    "\n",
    "```python\n",
    "# quantizacao_pytorch.py\n",
    "import torch\n",
    "import torch.quantization\n",
    "\n",
    "def quantizar_modelo_pytorch(model):\n",
    "    \"\"\"\n",
    "    Quantiza√ß√£o din√¢mica para PyTorch\n",
    "    Mais simples, sem necessidade de calibra√ß√£o\n",
    "    \"\"\"\n",
    "    # Modelo para CPU (quantiza√ß√£o funciona melhor em CPU)\n",
    "    model_cpu = model.cpu()\n",
    "    \n",
    "    # Quantiza√ß√£o din√¢mica (pesos INT8, ativa√ß√µes FP32)\n",
    "    model_quantized = torch.quantization.quantize_dynamic(\n",
    "        model_cpu,\n",
    "        {torch.nn.Linear, torch.nn.Conv2d},  # Camadas a quantizar\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    "    \n",
    "    # Comparar tamanhos\n",
    "    def get_model_size(model):\n",
    "        torch.save(model.state_dict(), \"temp.p\")\n",
    "        size = os.path.getsize(\"temp.p\") / (1024**2)\n",
    "        os.remove(\"temp.p\")\n",
    "        return size\n",
    "    \n",
    "    size_original = get_model_size(model_cpu)\n",
    "    size_quantized = get_model_size(model_quantized)\n",
    "    reducao = (1 - size_quantized/size_original) * 100\n",
    "    \n",
    "    print(f\"‚úì Modelo quantizado!\")\n",
    "    print(f\"  Original:    {size_original:.2f} MB\")\n",
    "    print(f\"  Quantizado:  {size_quantized:.2f} MB\")\n",
    "    print(f\"  Redu√ß√£o:     {reducao:.1f}%\")\n",
    "    \n",
    "    return model_quantized\n",
    "\n",
    "# Uso\n",
    "model_quantized = quantizar_modelo_pytorch(model)\n",
    "\n",
    "# Testar velocidade\n",
    "import time\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Original\n",
    "start = time.time()\n",
    "_ = model.cpu()(x)\n",
    "tempo_original = time.time() - start\n",
    "\n",
    "# Quantizado\n",
    "start = time.time()\n",
    "_ = model_quantized(x)\n",
    "tempo_quantizado = time.time() - start\n",
    "\n",
    "print(f\"\\nVelocidade:\")\n",
    "print(f\"  Original:    {tempo_original*1000:.2f} ms\")\n",
    "print(f\"  Quantizado:  {tempo_quantizado*1000:.2f} ms\")\n",
    "print(f\"  Speedup:     {tempo_original/tempo_quantizado:.2f}x\")\n",
    "```\n",
    "\n",
    "#### Quantization-Aware Training (QAT)\n",
    "\n",
    "Treinar o modelo **j√° a simular quantiza√ß√£o** - melhor precis√£o!\n",
    "\n",
    "```python\n",
    "# qat_tensorflow.py\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def treinar_com_qat(model, train_dataset, val_dataset, epochs=10):\n",
    "    \"\"\"\n",
    "    Quantization-Aware Training\n",
    "    Modelo aprende a compensar quantiza√ß√£o durante treino\n",
    "    \"\"\"\n",
    "    # Aplicar quantiza√ß√£o ao modelo\n",
    "    quantize_model = tfmot.quantization.keras.quantize_model\n",
    "    q_aware_model = quantize_model(model)\n",
    "    \n",
    "    # Compilar\n",
    "    q_aware_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"üéØ Treinando com Quantization-Aware Training...\")\n",
    "    \n",
    "    # Treinar\n",
    "    history = q_aware_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(patience=2)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Converter para TFLite INT8\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Guardar\n",
    "    with open('modelo_qat_int8.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(\"‚úì Modelo QAT treinado e quantizado!\")\n",
    "    \n",
    "    return q_aware_model, tflite_model\n",
    "\n",
    "# Instala√ß√£o necess√°ria:\n",
    "# pip install tensorflow-model-optimization\n",
    "```\n",
    "\n",
    "#### Compara√ß√£o: PTQ vs QAT\n",
    "\n",
    "| M√©todo | Facilidade | Tempo | Precis√£o | Quando Usar |\n",
    "|--------|-----------|-------|----------|-------------|\n",
    "| **PTQ** | ‚≠ê‚≠ê‚≠ê | R√°pido | Boa (-1-2%) | Modelo j√° treinado |\n",
    "| **QAT** | ‚≠ê‚≠ê | Lento | Melhor (-0.5%) | M√°xima precis√£o |\n",
    "\n",
    "**Recomenda√ß√£o para M1 16GB:**\n",
    "- Come√ßa com **PTQ** (post-training)\n",
    "- Se perderes muita precis√£o, tenta **QAT**\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Pruning e Compress√£o\n",
    "\n",
    "#### O que √© Pruning?\n",
    "\n",
    "**Pruning** = Remover pesos/neur√≥nios menos importantes do modelo.\n",
    "\n",
    "**Analogia:** √â como podar uma √°rvore - removes ramos que n√£o contribuem muito.\n",
    "\n",
    "```\n",
    "Modelo Original:           Modelo com Pruning:\n",
    "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          ‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà\n",
    "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚Üí     ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà\n",
    "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          ‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
    "                          (‚ñë = peso removido/zero)\n",
    "```\n",
    "\n",
    "**Vantagens:**\n",
    "- ‚úÖ Modelo mais pequeno\n",
    "- ‚úÖ Infer√™ncia mais r√°pida\n",
    "- ‚úÖ Menos mem√≥ria\n",
    "\n",
    "#### Magnitude-Based Pruning\n",
    "\n",
    "Remove pesos com menor valor absoluto:\n",
    "\n",
    "```python\n",
    "# pruning_tensorflow.py\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def pruning_progressivo(model, train_dataset, val_dataset):\n",
    "    \"\"\"\n",
    "    Pruning progressivo - remove pesos gradualmente durante treino\n",
    "    \"\"\"\n",
    "    # Definir schedule de pruning\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,      # Come√ßa sem pruning\n",
    "            final_sparsity=0.5,        # Termina com 50% dos pesos removidos\n",
    "            begin_step=0,\n",
    "            end_step=1000              # Ao longo de 1000 steps\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Aplicar pruning ao modelo\n",
    "    model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        model, \n",
    "        **pruning_params\n",
    "    )\n",
    "    \n",
    "    # Compilar\n",
    "    model_for_pruning.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks necess√°rios\n",
    "    callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),  # Atualiza m√°scara de pruning\n",
    "        tfmot.sparsity.keras.PruningSummaries(log_dir='logs'),  # Logs\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÇÔ∏è Treinando com Pruning Progressivo...\")\n",
    "    \n",
    "    # Treinar\n",
    "    history = model_for_pruning.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Remover wrappers de pruning\n",
    "    model_final = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    sparsity = calcular_sparsity(model_final)\n",
    "    print(f\"\\n‚úì Pruning conclu√≠do!\")\n",
    "    print(f\"  Sparsity: {sparsity:.1f}% (pesos zero)\")\n",
    "    \n",
    "    return model_final\n",
    "\n",
    "def calcular_sparsity(model):\n",
    "    \"\"\"Calcula percentagem de pesos zero\"\"\"\n",
    "    total_weights = 0\n",
    "    zero_weights = 0\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.kernel.numpy()\n",
    "            total_weights += weights.size\n",
    "            zero_weights += np.sum(weights == 0)\n",
    "    \n",
    "    return zero_weights / total_weights if total_weights > 0 else 0\n",
    "```\n",
    "\n",
    "**Combinar Pruning + Quantiza√ß√£o:**\n",
    "\n",
    "```python\n",
    "# pruning_e_quantizacao.py\n",
    "def otimizar_modelo_completo(model, train_dataset, val_dataset):\n",
    "    \"\"\"\n",
    "    Pipeline completo: Pruning ‚Üí Fine-tuning ‚Üí Quantiza√ß√£o\n",
    "    M√°xima compress√£o!\n",
    "    \"\"\"\n",
    "    print(\"üéØ PASSO 1: Pruning\")\n",
    "    model_pruned = self.aplicar_pruning(train_dataset, val_dataset)\n",
    "    \n",
    "    print(\"\\nüéØ PASSO 2: Fine-tuning\")\n",
    "    model_pruned.fit(train_dataset, validation_data=val_dataset, epochs=5, verbose=0)\n",
    "    \n",
    "    print(\"\\nüéØ PASSO 3: Quantiza√ß√£o\")\n",
    "    # Guardar temporariamente\n",
    "    model_pruned.save('temp_pruned.keras')\n",
    "    \n",
    "    # Quantizar\n",
    "    model_final = self.aplicar_quantizacao('temp_pruned.keras', train_dataset)\n",
    "    \n",
    "    # Comparar\n",
    "    tamanho_original = get_model_size(model)\n",
    "    tamanho_final = len(model_final) / (1024**2)\n",
    "    reducao = (1 - tamanho_final/tamanho_original) * 100\n",
    "    \n",
    "    print(f\"\\n‚úÖ OTIMIZA√á√ÉO COMPLETA!\")\n",
    "    print(f\"  Original:  {tamanho_original:.2f} MB\")\n",
    "    print(f\"  Final:     {tamanho_final:.2f} MB\")\n",
    "    print(f\"  Redu√ß√£o:   {reducao:.1f}%\")\n",
    "    \n",
    "    return model_final\n",
    "\n",
    "# Uso\n",
    "modelo_otimizado = otimizar_modelo_completo(model, train_ds, val_ds)\n",
    "```\n",
    "\n",
    "#### Knowledge Distillation\n",
    "\n",
    "Transferir conhecimento de um modelo grande (professor) para um pequeno (aluno):\n",
    "\n",
    "```python\n",
    "# knowledge_distillation.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class DistillationModel(keras.Model):\n",
    "    \"\"\"\n",
    "    Modelo que aprende tanto com labels reais como com professor\n",
    "    \"\"\"\n",
    "    def __init__(self, aluno, professor, alpha=0.1, temperatura=3):\n",
    "        super().__init__()\n",
    "        self.aluno = aluno\n",
    "        self.professor = professor\n",
    "        self.alpha = alpha          # Peso do professor\n",
    "        self.temperatura = temperatura\n",
    "        \n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        # Previs√µes do professor (soft targets)\n",
    "        professor_predictions = self.professor(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Previs√µes do aluno\n",
    "            aluno_predictions = self.aluno(x, training=True)\n",
    "            \n",
    "            # Loss com labels reais (hard targets)\n",
    "            loss_hard = self.loss_fn(y, aluno_predictions)\n",
    "            \n",
    "            # Loss com professor (soft targets)\n",
    "            # Temperatura suaviza probabilidades\n",
    "            soft_aluno = tf.nn.softmax(aluno_predictions / self.temperatura)\n",
    "            soft_professor = tf.nn.softmax(professor_predictions / self.temperatura)\n",
    "            \n",
    "            loss_soft = tf.reduce_mean(\n",
    "                tf.keras.losses.categorical_crossentropy(\n",
    "                    soft_professor, soft_aluno\n",
    "                )\n",
    "            ) * (self.temperatura ** 2)\n",
    "            \n",
    "            # Loss combinada\n",
    "            loss_total = self.alpha * loss_soft + (1 - self.alpha) * loss_hard\n",
    "        \n",
    "        # Backprop\n",
    "        gradients = tape.gradient(loss_total, self.aluno.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.aluno.trainable_variables))\n",
    "        \n",
    "        # Atualizar m√©tricas\n",
    "        self.compiled_metrics.update_state(y, aluno_predictions)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Uso\n",
    "# Professor: Modelo grande e preciso\n",
    "professor = keras.applications.ResNet50(weights='imagenet', include_top=True)\n",
    "professor.trainable = False\n",
    "\n",
    "# Aluno: Modelo pequeno\n",
    "aluno = keras.applications.MobileNetV2(weights=None, include_top=True)\n",
    "\n",
    "# Distillation\n",
    "distiller = DistillationModel(aluno, professor, alpha=0.1, temperatura=3)\n",
    "distiller.compile(optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinar aluno com conhecimento do professor\n",
    "distiller.fit(train_dataset, validation_data=val_dataset, epochs=20)\n",
    "\n",
    "# Guardar apenas o aluno\n",
    "aluno.save('modelo_aluno.keras')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Treino Eficiente\n",
    "\n",
    "#### Learning Rate Scheduling\n",
    "\n",
    "Ajustar learning rate durante treino para melhor converg√™ncia:\n",
    "\n",
    "```python\n",
    "# lr_schedulers.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1. ReduceLROnPlateau (reduz quando estagnar)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,           # Multiplica LR por 0.5\n",
    "    patience=3,           # Ap√≥s 3 epochs sem melhoria\n",
    "    min_lr=1e-7,         # LR m√≠nimo\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. CosineDecay (redu√ß√£o suave)\n",
    "lr_schedule = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=1000,\n",
    "    alpha=0.1  # LR final = initial √ó alpha\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# 3. ExponentialDecay\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.96  # Multiplica por 0.96 a cada 100 steps\n",
    ")\n",
    "\n",
    "# 4. Warm-up + Decay (personalizado)\n",
    "class WarmUpCosineDecay(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, warmup_steps, total_steps, initial_lr, target_lr):\n",
    "        super().__init__()\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.initial_lr = initial_lr\n",
    "        self.target_lr = target_lr\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            # Fase warm-up: aumenta LR linearmente\n",
    "            return (step / self.warmup_steps) * self.initial_lr\n",
    "        else:\n",
    "            # Fase decay: reduz com cosine\n",
    "            progress = (step - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "            cosine_decay = 0.5 * (1 + tf.cos(tf.constant(3.14159) * progress))\n",
    "            return self.target_lr + (self.initial_lr - self.target_lr) * cosine_decay\n",
    "\n",
    "# Uso\n",
    "lr_schedule = WarmUpCosineDecay(\n",
    "    warmup_steps=1000,\n",
    "    total_steps=10000,\n",
    "    initial_lr=1e-3,\n",
    "    target_lr=1e-6\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "```\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "Para quando o modelo n√£o melhora mais:\n",
    "\n",
    "```python\n",
    "# early_stopping.py\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',        # M√©trica a monitorizar\n",
    "    patience=10,               # Espera 10 epochs\n",
    "    restore_best_weights=True, # Volta aos melhores pesos\n",
    "    verbose=1,\n",
    "    min_delta=0.001           # Melhoria m√≠nima considerada\n",
    ")\n",
    "\n",
    "# Uso\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,  # M√°ximo (vai parar antes!)\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "```\n",
    "\n",
    "#### Checkpointing Estrat√©gico\n",
    "\n",
    "Guarda apenas os melhores modelos:\n",
    "\n",
    "```python\n",
    "# checkpointing.py\n",
    "# 1. Guardar melhor modelo\n",
    "checkpoint_best = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='melhor_modelo.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Guardar periodicamente\n",
    "checkpoint_periodic = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoint_epoch_{epoch:02d}.keras',\n",
    "    save_freq='epoch',\n",
    "    period=5  # A cada 5 epochs\n",
    ")\n",
    "\n",
    "# 3. Backup inteligente (guarda top-3)\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "class TopKCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor='val_accuracy', k=3):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.k = k\n",
    "        self.best_models = []  # (score, filepath)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "        \n",
    "        # Guardar modelo\n",
    "        self.model.save(filepath)\n",
    "        \n",
    "        # Adicionar √† lista\n",
    "        self.best_models.append((current, filepath))\n",
    "        self.best_models.sort(reverse=True, key=lambda x: x[0])\n",
    "        \n",
    "        # Manter apenas top-k\n",
    "        if len(self.best_models) > self.k:\n",
    "            _, to_delete = self.best_models.pop()\n",
    "            if os.path.exists(to_delete):\n",
    "                os.remove(to_delete)\n",
    "                print(f\"\\nüóëÔ∏è  Removido: {to_delete}\")\n",
    "\n",
    "# Uso\n",
    "top3 = TopKCheckpoint('modelo_epoch{epoch:02d}_acc{val_accuracy:.4f}.keras', k=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint_best, top3]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Pipeline Completo de Otimiza√ß√£o para M1\n",
    "\n",
    "```python\n",
    "# pipeline_otimizacao_m1.py\n",
    "class PipelineOtimizacaoM1:\n",
    "    \"\"\"\n",
    "    Pipeline completo de otimiza√ß√£o para M1 16GB\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model_original = model\n",
    "        self.model_otimizado = None\n",
    "        \n",
    "    def otimizar_completo(self, train_ds, val_ds):\n",
    "        \"\"\"\n",
    "        Aplica todas as otimiza√ß√µes na sequ√™ncia ideal\n",
    "        \"\"\"\n",
    "        print(\"üöÄ INICIANDO PIPELINE DE OTIMIZA√á√ÉO\\n\")\n",
    "        \n",
    "        # 1. Mixed Precision\n",
    "        print(\"üìä PASSO 1: Mixed Precision (FP16)\")\n",
    "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "        keras.mixed_precision.set_global_policy(policy)\n",
    "        print(\"‚úì Ativado\\n\")\n",
    "        \n",
    "        # 2. Pruning\n",
    "        print(\"‚úÇÔ∏è PASSO 2: Pruning (50% sparsity)\")\n",
    "        model_pruned = self.aplicar_pruning(train_ds, val_ds)\n",
    "        print(\"‚úì Conclu√≠do\\n\")\n",
    "        \n",
    "        # 3. Fine-tuning\n",
    "        print(\"üéØ PASSO 3: Fine-tuning\")\n",
    "        model_pruned.fit(train_ds, validation_data=val_ds, epochs=5, verbose=0)\n",
    "        print(\"‚úì Conclu√≠do\\n\")\n",
    "        \n",
    "        # 4. Quantiza√ß√£o\n",
    "        print(\"üî¢ PASSO 4: Quantiza√ß√£o INT8\")\n",
    "        model_pruned.save('temp_pruned.keras')\n",
    "        model_quantizado = self.aplicar_quantizacao('temp_pruned.keras', train_ds)\n",
    "        print(\"‚úì Conclu√≠do\\n\")\n",
    "        \n",
    "        # Relat√≥rio final\n",
    "        self.gerar_relatorio(model_quantizado)\n",
    "        \n",
    "        self.model_otimizado = model_quantizado\n",
    "        return model_quantizado\n",
    "    \n",
    "    def aplicar_pruning(self, train_ds, val_ds):\n",
    "        # ... (c√≥digo de pruning do exemplo anterior)\n",
    "        pass\n",
    "    \n",
    "    def aplicar_quantizacao(self, model_path, train_ds):\n",
    "        # ... (c√≥digo de quantiza√ß√£o do exemplo anterior)\n",
    "        pass\n",
    "    \n",
    "    def gerar_relatorio(self, model_final):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"RELAT√ìRIO FINAL DE OTIMIZA√á√ÉO\")\n",
    "        print(\"=\" * 60)\n",
    "        # Compara√ß√µes de tamanho, velocidade, precis√£o\n",
    "        pass\n",
    "\n",
    "# Uso\n",
    "pipeline = PipelineOtimizacaoM1(model)\n",
    "modelo_otimizado = pipeline.otimizar_completo(train_dataset, val_dataset)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Checklist M√≥dulo 4\n",
    "\n",
    "- [ ] Entendo diferen√ßa entre FP32, FP16, INT8\n",
    "- [ ] Consigo fazer quantiza√ß√£o post-training (PTQ)\n",
    "- [ ] Sei aplicar pruning progressivo\n",
    "- [ ] Conhe√ßo knowledge distillation\n",
    "- [ ] Implementei learning rate scheduling\n",
    "- [ ] Uso early stopping e checkpointing\n",
    "- [ ] Consigo combinar t√©cnicas (pruning + quantiza√ß√£o)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Pr√≥ximos Passos\n",
    "\n",
    "No **M√≥dulo 5**, vamos finalmente trabalhar com LLMs (Large Language Models)! Vais aprender a fazer fine-tuning de modelos at√© 7B par√¢metros no M1 16GB usando LoRA e QLoRA!\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
