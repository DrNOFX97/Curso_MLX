{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 6.2 Core ML\n",
    "\n",
    "#### O que Ã© Core ML?\n",
    "\n",
    "**Core ML** = Framework da Apple para executar modelos de AA em dispositivos Apple.\n",
    "\n",
    "**Vantagens:**\n",
    "- âœ… Optimizado para todos os chips Apple (M-series)\n",
    "- âœ… Usa Neural Engine automaticamente\n",
    "- âœ… IntegraÃ§Ã£o perfeita com apps iOS/macOS\n",
    "- âœ… Privacidade (tudo on-device)\n",
    "- âœ… Baixo consumo energÃ©tico\n",
    "\n",
    "**Quando usar Core ML:**\n",
    "- Apps iOS/macOS que precisam de AA\n",
    "- InferÃªncia em produÃ§Ã£o\n",
    "- Privacidade Ã© crÃ­tica\n",
    "- Modelos pequenos/mÃ©dios (<1GB)\n",
    "\n",
    "#### Converter Modelos para Core ML\n",
    "\n",
    "```python\n",
    "# converter_coreml.py\n",
    "import coremltools as ct\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os # Import os for os.path.getsize\n",
    "\n",
    "class ConversorCoreML:\n",
    "    \"\"\"\n",
    "    Converte modelos TensorFlow/PyTorch para Core ML\n",
    "    \"\"\"\n",
    "    \n",
    "    def converter_keras(self, modelo_path, output_path=\"modelo.mlmodel\"):\n",
    "        \"\"\"\n",
    "        Converte modelo Keras para Core ML\n",
    "        \"\"\"\n",
    "        print(f\"ðŸ”„ Convertendo {modelo_path} para Core ML...\")\n",
    "        \n",
    "        # Carregar modelo\n",
    "        model = keras.models.load_model(modelo_path)\n",
    "        \n",
    "        # Converter\n",
    "        mlmodel = ct.convert(\n",
    "            model,\n",
    "            inputs=[ct.ImageType(shape=(1, 224, 224, 3))],\n",
    "            convert_to=\"mlprogram\",  # Formato moderno\n",
    "            compute_precision=ct.precision.FLOAT16  # Mais eficiente\n",
    "        )\n",
    "        \n",
    "        # Adicionar metadados\n",
    "        mlmodel.author = \"Teu Nome\"\n",
    "        mlmodel.short_description = \"Classificador de imagens\"\n",
    "        mlmodel.version = \"1.0\"\n",
    "        \n",
    "        # Guardar\n",
    "        mlmodel.save(output_path)\n",
    "        \n",
    "        print(f\"âœ“ Modelo convertido: {output_path}\")\n",
    "        print(f\"  Tamanho: {os.path.getsize(output_path) / (1024**2):.1f} MB\")\n",
    "        \n",
    "        return mlmodel\n",
    "    \n",
    "    def converter_pytorch(self, model, exemplo_input, output_path=\"modelo.mlmodel\"):\n",
    "        \"\"\"\n",
    "        Converte modelo PyTorch para Core ML\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        \n",
    "        print(\"ðŸ”„ Convertendo PyTorch para Core ML...\")\n",
    "        \n",
    "        # Colocar em modo eval\n",
    "        model.eval()\n",
    "        \n",
    "        # TraÃ§ar modelo\n",
    "        traced_model = torch.jit.trace(model, exemplo_input)\n",
    "        \n",
    "        # Converter\n",
    "        mlmodel = ct.convert(\n",
    "            traced_model,\n",
    "            inputs=[ct.TensorType(shape=exemplo_input.shape)],\n",
    "            convert_to=\"mlprogram\",\n",
    "            compute_precision=ct.precision.FLOAT16\n",
    "        )\n",
    "        \n",
    "        mlmodel.save(output_path)\n",
    "        print(f\"âœ“ Modelo convertido: {output_path}\")\n",
    "        \n",
    "        return mlmodel\n",
    "    \n",
    "    def optimizar_para_neural_engine(self, mlmodel):\n",
    "        \"\"\"\n",
    "        Optimiza modelo para Neural Engine\n",
    "        \"\"\"\n",
    "        print(\"\\nâš¡ Optimizando para Neural Engine...\")\n",
    "        \n",
    "        # ConfiguraÃ§Ãµes recomendadas\n",
    "        mlmodel = ct.compression_utils.quantize_weights(\n",
    "            mlmodel,\n",
    "            nbits=8,\n",
    "            quantization_mode=\"linear\"\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ OptimizaÃ§Ã£o completa!\")\n",
    "        print(\"  - QuantizaÃ§Ã£o 8-bit aplicada\")\n",
    "        print(\"  - Preparado para Neural Engine\")\n",
    "        \n",
    "        return mlmodel\n",
    "\n",
    "# InstalaÃ§Ã£o necessÃ¡ria:\n",
    "# pip install coremltools\n",
    "\n",
    "# Exemplo de uso\n",
    "conversor = ConversorCoreML()\n",
    "\n",
    "# Converter modelo Keras\n",
    "modelo_coreml = conversor.converter_keras(\n",
    "    \"classificador_final.keras\",\n",
    "    \"ClassificadorImagens.mlmodel\"\n",
    ")\n",
    "\n",
    "# Optimizar\n",
    "modelo_optimizado = conversor.optimizar_para_neural_engine(modelo_coreml)\n",
    "modelo_optimizado.save(\"ClassificadorImagens_Optimizado.mlmodel\")\n",
    "```\n",
    "\n",
    "#### Usar Core ML em Python\n",
    "\n",
    "```python\n",
    "# usar_coreml.py\n",
    "import coremltools as ct\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class InferenciaCoreML:\n",
    "    \"\"\"\n",
    "    Executa inferÃªncia com modelos Core ML\n",
    "    \"\"\"\n",
    "    def __init__(self, modelo_path):\n",
    "        self.modelo_path = modelo_path\n",
    "        self.model = None\n",
    "    \n",
    "    def carregar(self):\n",
    "        \"\"\"\n",
    "        Carrega modelo Core ML\n",
    "        \"\"\"\n",
    "        print(f\"ðŸ“¥ Carregando {self.modelo_path}...\")\n",
    "        self.model = ct.models.MLModel(self.modelo_path)\n",
    "        \n",
    "        # InformaÃ§Ã£o do modelo\n",
    "        spec = self.model.get_spec()\n",
    "        print(f\"âœ“ Modelo carregado!\")\n",
    "        print(f\"  DescriÃ§Ã£o: {spec.description}\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def prever_imagem(self, imagem_path):\n",
    "        \"\"\"\n",
    "        Faz previsÃ£o em imagem\n",
    "        \"\"\"\n",
    "        # Carregar e preparar imagem\n",
    "        img = Image.open(imagem_path).resize((224, 224))\n",
    "        img_array = np.array(img).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Prever\n",
    "        resultado = self.model.predict({'image': img_array})\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def benchmark(self, num_runs=100):\n",
    "        \"\"\"\n",
    "        Mede desempenho do modelo\n",
    "        \"\"\"\n",
    "        import time\n",
    "        \n",
    "        print(f\"\\nâš¡ Benchmark ({num_runs} execuÃ§Ãµes)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Criar input dummy\n",
    "        dummy_input = np.random.rand(224, 224, 3).astype(np.float32)\n",
    "        \n",
    "        # Warm-up\n",
    "        for _ in range(10):\n",
    "            _ = self.model.predict({'image': dummy_input})\n",
    "        \n",
    "        # Benchmark\n",
    "        start = time.time()\n",
    "        for _ in range(num_runs):\n",
    "            _ = self.model.predict({'image': dummy_input})\n",
    "        tempo_total = time.time() - start\n",
    "        \n",
    "        tempo_medio = (tempo_total / num_runs) * 1000\n",
    "        fps = num_runs / tempo_total\n",
    "        \n",
    "        print(f\"Tempo mÃ©dio: {tempo_medio:.2f} ms\")\n",
    "        print(f\"FPS: {fps:.1f}\")\n",
    "        print(f\"Throughput: {1000/tempo_medio:.1f} inferÃªncias/segundo\")\n",
    "\n",
    "# Uso\n",
    "inferencia = InferenciaCoreML(\"ClassificadorImagens.mlmodel\")\n",
    "inferencia.carregar()\n",
    "\n",
    "# Prever\n",
    "resultado = inferencia.prever_imagem(\"teste.jpg\")\n",
    "print(f\"\\nPrevisÃ£o: {resultado}\")\n",
    "\n",
    "# Benchmark\n",
    "inferencia.benchmark(num_runs=100)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6.3 MonitorizaÃ§Ã£o e Debugging\n",
    "\n",
    "#### TensorBoard\n",
    "\n",
    "```python\n",
    "# tensorboard_avancado.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "\n",
    "class MonitorizacaoTensorBoard:\n",
    "    \"\"\"\n",
    "    MonitorizaÃ§Ã£o avanÃ§ada com TensorBoard\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir=\"logs\"):\n",
    "        self.log_dir = f\"{log_dir}/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        self.callbacks = []\n",
    "    \n",
    "    def configurar_callbacks(self):\n",
    "        \"\"\"\n",
    "        Configura callbacks do TensorBoard\n",
    "        \"\"\"\n",
    "        # Callback bÃ¡sico\n",
    "        tensorboard = keras.callbacks.TensorBoard(\n",
    "            log_dir=self.log_dir,\n",
    "            histogram_freq=1,        # Histogramas dos pesos\n",
    "            write_graph=True,        # GrÃ¡fico do modelo\n",
    "            write_images=True,       # VisualizaÃ§Ã£o de features\n",
    "            update_freq='epoch',     # FrequÃªncia de actualizaÃ§Ã£o\n",
    "            profile_batch='10,20'    # Profiling de performance\n",
    "        )\n",
    "        \n",
    "        self.callbacks.append(tensorboard)\n",
    "        \n",
    "        # Callback personalizado para mÃ©tricas extras\n",
    "        class MetricasPersonalizadas(keras.callbacks.Callback):\n",
    "            def __init__(self, log_dir):\n",
    "                super().__init__()\n",
    "                self.file_writer = tf.summary.create_file_writer(log_dir + '/custom')\n",
    "            \n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                with self.file_writer.as_default():\n",
    "                    # Learning rate actual\n",
    "                    lr = self.model.optimizer.learning_rate\n",
    "                    if hasattr(lr, 'numpy'):\n",
    "                        tf.summary.scalar('learning_rate', lr.numpy(), step=epoch)\n",
    "                    \n",
    "                    # Norma dos gradientes (detectar problemas)\n",
    "                    if logs and 'gradient_norm' in logs:\n",
    "                        tf.summary.scalar('gradient_norm', logs['gradient_norm'], step=epoch)\n",
    "                \n",
    "                self.file_writer.flush()\n",
    "        \n",
    "        self.callbacks.append(MetricasPersonalizadas(self.log_dir))\n",
    "        \n",
    "        print(f\"âœ“ TensorBoard configurado\")\n",
    "        print(f\"  Log dir: {self.log_dir}\")\n",
    "        print(f\"  Para visualizar: tensorboard --logdir={self.log_dir}\")\n",
    "        \n",
    "        return self.callbacks\n",
    "\n",
    "# Uso\n",
    "monitor = MonitorizacaoTensorBoard()\n",
    "cbks = monitor.configurar_callbacks()\n",
    "\n",
    "# Treinar modelo\n",
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     epochs=50,\n",
    "#     callbacks=cbks\n",
    "# )\n",
    "\n",
    "print(\"\\nðŸ“Š Para ver os resultados:\")\n",
    "print(f\"   tensorboard --logdir={monitor.log_dir}\")\n",
    "```\n",
    "\n",
    "#### Weights & Biases (wandb)\n",
    "\n",
    "```python\n",
    "# wandb_integracao.py\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from datetime import datetime # Already imported above, but good to have here for clarity\n",
    "\n",
    "class MonitorizacaoWandB:\n",
    "    \"\"\"\n",
    "    IntegraÃ§Ã£o com Weights & Biases\n",
    "    Melhor que TensorBoard para experimentos mÃºltiplos\n",
    "    \"\"\"\n",
    "    def __init__(self, projeto=\"treino-m1\", nome_experimento=None):\n",
    "        self.projeto = projeto\n",
    "        self.nome = nome_experimento or f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    def inicializar(self, config):\n",
    "        \"\"\"\n",
    "        Inicializa tracking do wandb\n",
    "        \n",
    "        Args:\n",
    "            config: DicionÃ¡rio com hiperparÃ¢metros\n",
    "        \"\"\"\n",
    "        wandb.init(\n",
    "            project=self.projeto,\n",
    "            name=self.nome,\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ W&B inicializado\")\n",
    "        print(f\"  Projecto: {self.projeto}\")\n",
    "        print(f\"  Experimento: {self.nome}\")\n",
    "        print(f\"  URL: {wandb.run.url}\")\n",
    "    \n",
    "    def criar_callback(self):\n",
    "        \"\"\"\n",
    "        Cria callback para Keras\n",
    "        \"\"\"\n",
    "        return WandbCallback(\n",
    "            save_model=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max'\n",
    "        )\n",
    "    \n",
    "    def registar_metricas(self, metricas, step=None):\n",
    "        \"\"\"\n",
    "        Regista mÃ©tricas personalizadas\n",
    "        \"\"\"\n",
    "        wandb.log(metricas, step=step)\n",
    "    \n",
    "    def registar_modelo(self, modelo_path):\n",
    "        \"\"\"\n",
    "        Regista modelo final\n",
    "        \"\"\"\n",
    "        artifact = wandb.Artifact('modelo', type='model')\n",
    "        artifact.add_file(modelo_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "        \n",
    "        print(f\"âœ“ Modelo registado no W&B\")\n",
    "\n",
    "# InstalaÃ§Ã£o: \n",
    "# pip install wandb\n",
    "\n",
    "# Uso\n",
    "# config = {\n",
    "#     'learning_rate': 0.001,\n",
    "#     'batch_size': 32,\n",
    "#     'epochs': 50,\n",
    "#     'arquitetura': 'MobileNetV2',\n",
    "#     'dataset': 'custom_animals'\n",
    "# }\n",
    "\n",
    "# monitor = MonitorizacaoWandB(projeto=\"classificador-animais\")\n",
    "# monitor.inicializar(config)\n",
    "\n",
    "# Treinar\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     epochs=config['epochs'],\n",
    "#     callbacks=[monitor.criar_callback()]\n",
    "# )\n",
    "# Registar modelo final\n",
    "# monitor.registar_modelo('modelo_final.keras')\n",
    "\n",
    "# Terminar\n",
    "# wandb.finish()\n",
    "```\n",
    "\n",
    "#### Profiling de Desempenho\n",
    "\n",
    "```python\n",
    "# profiling_m1.py\n",
    "import time\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class ProfilerM1:\n",
    "    \"\"\"\n",
    "    Profile de desempenho especÃ­fico para M1\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metricas = []\n",
    "    \n",
    "    @contextmanager\n",
    "    def profile_block(self, nome):\n",
    "        \"\"\"\n",
    "        Context manager para profile de blocos de cÃ³digo\n",
    "        \"\"\"\n",
    "        print(f\"\\nâ±ï¸  Profiling: {nome}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # MÃ©tricas iniciais\n",
    "        mem_antes = psutil.virtual_memory().used / (1024**3)\n",
    "        start = time.time()\n",
    "        \n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            # MÃ©tricas finais\n",
    "            tempo = time.time() - start\n",
    "            mem_depois = psutil.virtual_memory().used / (1024**3)\n",
    "            mem_usada = mem_depois - mem_antes\n",
    "            \n",
    "            resultado = {\n",
    "                'nome': nome,\n",
    "                'tempo': tempo,\n",
    "                'memoria_usada_gb': mem_usada\n",
    "            }\n",
    "            \n",
    "            self.metricas.append(resultado)\n",
    "            \n",
    "            print(f\"Tempo: {tempo:.2f}s\")\n",
    "            print(f\"MemÃ³ria usada: {mem_usada:.2f} GB\")\n",
    "    \n",
    "    def relatorio(self):\n",
    "        \"\"\"\n",
    "        Gera relatÃ³rio final de profiling\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ðŸ“Š RELATÃ“RIO DE PROFILING\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metrica in self.metricas:\n",
    "            print(f\"\\n{metrica['nome']}:\")\n",
    "            print(f\"  Tempo: {metrica['tempo']:.2f}s\")\n",
    "            print(f\"  MemÃ³ria: {metrica['memoria_usada_gb']:.2f} GB\")\n",
    "        \n",
    "        # Tempo total\n",
    "        tempo_total = sum(m['tempo'] for m in self.metricas)\n",
    "        print(f\"\\nâ±ï¸  Tempo total: {tempo_total:.2f}s\")\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
