{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso: Como Treinar Modelos de Aprendizagem AutomÃ¡tica (Machine Learning) no MacBook Pro M1 16GB\n",
    "\n",
    "## MÃ³dulo 1: PreparaÃ§Ã£o do Ambiente\n",
    "\n",
    "### 1.1 IntroduÃ§Ã£o ao chip Apple Silicon M1\n",
    "\n",
    "#### Arquitetura ARM vs x86\n",
    "O chip M1 da Apple representa uma mudanÃ§a fundamental na computaÃ§Ã£o pessoal:\n",
    "\n",
    "**Arquitetura ARM:**\n",
    "- O M1 usa arquitetura ARM64, nÃ£o x86 como os processadores Intel\n",
    "- Mais eficiente energeticamente (RISC vs CISC)\n",
    "- Alguns programas precisam de ser recompilados ou usar Rosetta 2 (camada de traduÃ§Ã£o)\n",
    "- Para ML: bibliotecas nativas ARM tÃªm desempenho muito superior\n",
    "\n",
    "**DiferenÃ§as prÃ¡ticas:**\n",
    "- BinÃ¡rios x86 funcionam via Rosetta 2, mas sÃ£o mais lentos\n",
    "- Python compilado para ARM Ã© atÃ© 2-3x mais rÃ¡pido\n",
    "- Nunca uses Python do python.org (Ã© x86) - usa Miniforge!\n",
    "\n",
    "#### GPU Integrada e Neural Engine\n",
    "\n",
    "**GPU (7 ou 8 nÃºcleos no M1):**\n",
    "- Totalmente integrada com a CPU (Unified Memory Architecture)\n",
    "- Acesso direto Ã  RAM sem transferÃªncias CPUâ†”GPU\n",
    "- Framework Metal para aceleraÃ§Ã£o GPU\n",
    "- Ideal para treino de modelos pequenos/mÃ©dios\n",
    "\n",
    "**Neural Engine (16 nÃºcleos):**\n",
    "- Chip dedicado para operaÃ§Ãµes de ML\n",
    "- 11 TFLOPS de desempenho\n",
    "- Usado principalmente para inferÃªncia (Core ML)\n",
    "- Menos flexÃ­vel que GPU, mas muito eficiente\n",
    "\n",
    "#### Vantagens para Aprendizagem AutomÃ¡tica\n",
    "\n",
    "1. **Unified Memory Architecture (UMA):**\n",
    "   - CPU e GPU partilham os mesmos 16GB de RAM\n",
    "   - Sem overhead de transferÃªncias de dados\n",
    "   - Batch sizes maiores que GPUs dedicadas com VRAM limitada\n",
    "\n",
    "2. **EficiÃªncia EnergÃ©tica:**\n",
    "   - Treino prolongado sem sobreaquecimento\n",
    "   - Bateria dura horas mesmo em treino intensivo\n",
    "\n",
    "3. **Desempenho Surpreendente:**\n",
    "   - Para modelos atÃ© ~7B parÃ¢metros, competitivo com GPUs mid-range\n",
    "   - Excelente para prototipagem e experimentaÃ§Ã£o\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 ConfiguraÃ§Ã£o Inicial\n",
    "\n",
    "#### Passo 1: Instalar Homebrew\n",
    "\n",
    "Homebrew Ã© o gestor de pacotes essencial para macOS. Abre o Terminal e executa:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ApÃ³s instalaÃ§Ã£o, adiciona ao PATH (o instalador mostrarÃ¡ os comandos exatos):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"' >> ~/.zshrc\n",
    "eval \"$(/opt/homebrew/bin/brew shellenv)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica a instalaÃ§Ã£o:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "brew --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 2: Instalar Miniforge (Python para ARM)\n",
    "\n",
    "**IMPORTANTE:** Nunca uses o Python do python.org no M1! Usa Miniforge (Conda otimizado para ARM)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download do Miniforge\n",
    "brew install miniforge\n",
    "\n",
    "# Inicializar conda\n",
    "conda init zsh\n",
    "\n",
    "# Reinicia o terminal ou executa:\n",
    "source ~/.zshrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica que estÃ¡s a usar Python ARM:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python -c \"import platform; print(platform.machine())\"\n",
    "# Deve retornar: arm64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3: Criar Ambiente Virtual Base\n",
    "\n",
    "Cria um ambiente dedicado para ML:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Criar ambiente com Python 3.11\n",
    "conda create -n ml-m1 python=3.11 -y\n",
    "\n",
    "# Ativar ambiente\n",
    "conda activate ml-m1\n",
    "\n",
    "# Instalar pacotes base\n",
    "conda install -c conda-forge numpy pandas matplotlib scikit-learn jupyter -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configurar ambiente como padrÃ£o:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Adiciona ao ~/.zshrc para ativar automaticamente\n",
    "echo \"conda activate ml-m1\" >> ~/.zshrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 4: Ferramentas de Desenvolvimento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Git (se ainda nÃ£o tiveres)\n",
    "brew install git\n",
    "\n",
    "# Editor de cÃ³digo (opcional)\n",
    "brew install --cask visual-studio-code\n",
    "\n",
    "# Ferramentas de monitorizaÃ§Ã£o\n",
    "brew install htop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.3 Frameworks Otimizados para M1\n",
    "\n",
    "#### TensorFlow Metal\n",
    "\n",
    "TensorFlow com aceleraÃ§Ã£o GPU via Metal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda activate ml-m1\n",
    "\n",
    "# Instalar TensorFlow e plugin Metal\n",
    "pip install tensorflow==2.20.0\n",
    "pip install tensorflow-metal==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testar aceleraÃ§Ã£o GPU:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar dispositivos disponÃ­veis\n",
    "print(\"Dispositivos disponÃ­veis:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Deve mostrar GPU\n",
    "print(\"\\nGPU disponÃ­vel:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "\n",
    "# Teste de performance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Criar dados aleatÃ³rios\n",
    "x = tf.random.normal([10000, 10000])\n",
    "\n",
    "# OperaÃ§Ã£o na GPU\n",
    "start = time.time()\n",
    "y = tf.matmul(x, x)\n",
    "gpu_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTempo de multiplicaÃ§Ã£o de matrizes (10000x10000): {gpu_time:.4f}s\")\n",
    "print(\"âœ“ TensorFlow Metal estÃ¡ a funcionar!\" if gpu_time < 1.0 else \"âš  Performance abaixo do esperado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch com MPS (Metal Performance Shaders)\n",
    "\n",
    "PyTorch com suporte nativo para GPU do M1:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda activate ml-m1\n",
    "\n",
    "# Instalar PyTorch com suporte MPS\n",
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testar aceleraÃ§Ã£o MPS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Verificar disponibilidade do MPS\n",
    "print(\"MPS disponÃ­vel:\", torch.backends.mps.is_available())\n",
    "print(\"MPS construÃ­do:\", torch.backends.mps.is_built())\n",
    "\n",
    "# Definir dispositivo\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Teste de performance\n",
    "import time\n",
    "\n",
    "x = torch.randn(10000, 10000, device=device)\n",
    "\n",
    "start = time.time()\n",
    "y = torch.matmul(x, x)\n",
    "torch.mps.synchronize()  # Esperar GPU terminar\n",
    "mps_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTempo de multiplicaÃ§Ã£o de matrizes: {mps_time:.4f}s\")\n",
    "print(\"âœ“ PyTorch MPS estÃ¡ a funcionar!\" if mps_time < 1.0 else \"âš  Performance abaixo do esperado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ComparaÃ§Ã£o: TensorFlow vs PyTorch no M1\n",
    "\n",
    "| Aspecto | TensorFlow Metal | PyTorch MPS |\n",
    "|---------|-----------------|-----------------|\n",
    "| **Maturidade M1** | Muito estÃ¡vel | EstÃ¡vel (melhorou muito) |\n",
    "| **Desempenho** | Excelente | Excelente |\n",
    "| **Compatibilidade** | Alta | Algumas operaÃ§Ãµes nÃ£o suportadas |\n",
    "| **Comunidade** | Maior | A crescer rapidamente |\n",
    "| **RecomendaÃ§Ã£o** | Projetos de produÃ§Ã£o | Pesquisa e prototipagem |\n",
    "\n",
    "#### JAX com Metal (Opcional - AvanÃ§ado)\n",
    "\n",
    "A Apple lanÃ§ou suporte oficial para JAX com aceleraÃ§Ã£o Metal! Ideal para pesquisa e computaÃ§Ã£o numÃ©rica de alto desempenho.\n",
    "\n",
    "**InstalaÃ§Ã£o:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda activate ml-m1\n",
    "\n",
    "# Instalar JAX com plugin Metal da Apple\n",
    "pip install jax-metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto instala automaticamente o JAX e o plugin Metal otimizado.\n",
    "\n",
    "**Testar aceleraÃ§Ã£o Metal:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Verificar dispositivos\n",
    "print(\"Dispositivos JAX:\", jax.devices())\n",
    "print(\"Dispositivo padrÃ£o:\", jax.default_backend())\n",
    "\n",
    "# Teste de performance\n",
    "import time\n",
    "\n",
    "x = jax.random.normal(jax.random.PRNGKey(0), (10000, 10000))\n",
    "\n",
    "# JIT compile para otimizaÃ§Ã£o\n",
    "@jax.jit\n",
    "def matrix_multiply(a):\n",
    "    return jnp.matmul(a, a)\n",
    "\n",
    "# Warm-up (primeira execuÃ§Ã£o compila)\n",
    "_ = matrix_multiply(x)\n",
    "\n",
    "# Benchmark\n",
    "start = time.time()\n",
    "result = matrix_multiply(x)\n",
    "result.block_until_ready()  # Esperar GPU terminar\n",
    "jax_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTempo de multiplicaÃ§Ã£o de matrizes: {jax_time:.4f}s\")\n",
    "print(\"âœ“ JAX Metal estÃ¡ a funcionar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quando usar JAX:**\n",
    "- Pesquisa que requer diferenciaÃ§Ã£o automÃ¡tica avanÃ§ada\n",
    "- CÃ³digo cientÃ­fico que precisa de ser muito otimizado\n",
    "- Quando queres controlo fino sobre transformaÃ§Ãµes (vmap, pmap, etc.)\n",
    "- Treino com XLA (compilaÃ§Ã£o otimizada)\n",
    "\n",
    "**DocumentaÃ§Ã£o oficial:** https://developer.apple.com/metal/jax/\n",
    "\n",
    "#### VerificaÃ§Ã£o Final do Ambiente\n",
    "\n",
    "Cria um script de teste completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste_ambiente.py\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Arquitetura: {sys.platform}\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"âœ“ TensorFlow: {tf.__version__}\")\n",
    "    print(f\"  GPU disponÃ­vel: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— TensorFlow nÃ£o instalado\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ“ PyTorch: {torch.__version__}\")\n",
    "    print(f\"  MPS disponÃ­vel: {torch.backends.mps.is_available()}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— PyTorch nÃ£o instalado\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"âœ“ NumPy: {np.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— NumPy nÃ£o instalado\")\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(f\"âœ“ Pandas: {pd.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— Pandas nÃ£o instalado\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python teste_ambiente.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### âœ… Checklist MÃ³dulo 1\n",
    "\n",
    "- [ ] Homebrew instalado\n",
    "- [ ] Miniforge instalado (Python ARM)\n",
    "- [ ] Ambiente virtual `ml-m1` criado\n",
    "- [ ] TensorFlow Metal instalado e testado\n",
    "- [ ] PyTorch MPS instalado e testado\n",
    "- [ ] Script de teste executado com sucesso\n",
    "- [ ] GPU/MPS a funcionar corretamente\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ PrÃ³ximos Passos\n",
    "\n",
    "No **MÃ³dulo 2**, vamos aprender a gerir eficientemente os 16GB de RAM e monitorizar recursos durante o treino!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
