{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M\u00f3dulo 9: Recursos Adicionais\n",
    "\n",
    "## \ud83d\udccb \u00cdndice\n",
    "\n",
    "### 9.1 Comunidades e Suporte\n",
    "- F\u00f3runs especializados\n",
    "- Comunidades portuguesas\n",
    "- Discord/Slack\n",
    "- GitHub Discussions\n",
    "\n",
    "### 9.2 Leitura Complementar\n",
    "- Documenta\u00e7\u00e3o oficial\n",
    "- Papers fundamentais\n",
    "- Blogs t\u00e9cnicos\n",
    "- Newsletters\n",
    "\n",
    "### 9.3 Actualiza\u00e7\u00f5es e Futuro\n",
    "- M2/M3/M4 - Diferen\u00e7as\n",
    "- Novas vers\u00f5es de frameworks\n",
    "- Tend\u00eancias em Edge ML\n",
    "- Roadmap de aprendizagem\n",
    "\n",
    "---\n",
    "\n",
    "## 9.1 Comunidades e Suporte\n",
    "\n",
    "### F\u00f3runs e Comunidades Globais\n",
    "\n",
    "**Stack Overflow**\n",
    "```\n",
    "\ud83d\udd17 https://stackoverflow.com/questions/tagged/apple-silicon\n",
    "\n",
    "Melhor para:\n",
    "- Problemas t\u00e9cnicos espec\u00edficos\n",
    "- Erros de c\u00f3digo\n",
    "- Configura\u00e7\u00f5es\n",
    "\n",
    "Dicas:\n",
    "\u2705 Pesquisa antes de perguntar (90% j\u00e1 foi respondido)\n",
    "\u2705 Inclui c\u00f3digo m\u00ednimo reprodut\u00edvel\n",
    "\u2705 Especifica vers\u00f5es (TensorFlow, Python, macOS)\n",
    "\u274c Evita perguntas abertas (\"qual \u00e9 melhor?\")\n",
    "```\n",
    "\n",
    "**Hugging Face Forums**\n",
    "```\n",
    "\ud83d\udd17 https://discuss.huggingface.co/\n",
    "\n",
    "Melhor para:\n",
    "- Transformers e LLMs\n",
    "- Fine-tuning\n",
    "- Problemas com modelos espec\u00edficos\n",
    "\n",
    "Tags \u00fateis:\n",
    "#apple-silicon\n",
    "#mlx\n",
    "#optimization\n",
    "```\n",
    "\n",
    "**Reddit**\n",
    "```\n",
    "\ud83d\udd17 r/MachineLearning\n",
    "\ud83d\udd17 r/LocalLLaMA (para LLMs)\n",
    "\ud83d\udd17 r/MLQuestions\n",
    "\n",
    "Melhor para:\n",
    "- Discuss\u00f5es gerais\n",
    "- Compara\u00e7\u00f5es de modelos\n",
    "- Not\u00edcias e papers\n",
    "\n",
    "Evita:\n",
    "\u274c Homework help (use r/learnmachinelearning)\n",
    "\u274c Self-promotion excessivo\n",
    "```\n",
    "\n",
    "**GitHub Discussions**\n",
    "```\n",
    "Reposit\u00f3rios importantes:\n",
    "\ud83d\udd17 tensorflow/tensorflow\n",
    "\ud83d\udd17 pytorch/pytorch\n",
    "\ud83d\udd17 ml-explore/mlx\n",
    "\ud83d\udd17 huggingface/transformers\n",
    "\n",
    "Melhor para:\n",
    "- Bugs reportados\n",
    "- Feature requests\n",
    "- Issues espec\u00edficos do M1\n",
    "```\n",
    "\n",
    "### Comunidades Portuguesas\n",
    "\n",
    "**Portuguese AI Community**\n",
    "```\n",
    "\ud83d\udd17 Discord: https://discord.gg/portuguese-ai\n",
    "\ud83d\udd17 Telegram: @PortugalAI\n",
    "\n",
    "T\u00f3picos:\n",
    "- ML/DL em portugu\u00eas\n",
    "- Eventos em Portugal\n",
    "- Oportunidades de trabalho\n",
    "- Projectos colaborativos\n",
    "\n",
    "Canais \u00fateis:\n",
    "#ajuda-tecnica\n",
    "#recursos\n",
    "#papers-pt\n",
    "#projectos\n",
    "```\n",
    "\n",
    "**NOVA IMS / IST / FEUP - Grupos de Alunos**\n",
    "```\n",
    "Grupos acad\u00e9micos em PT:\n",
    "- NOVA Data Science Club\n",
    "- IST AI Student Group\n",
    "- FEUP AI & Robotics\n",
    "\n",
    "Contacto via:\n",
    "- LinkedIn\n",
    "- Instagram oficial das faculdades\n",
    "- Eventos (talks, workshops)\n",
    "```\n",
    "\n",
    "**Meetups e Eventos Portugal**\n",
    "```\n",
    "\ud83d\udd17 Meetup.com\n",
    "   - Lisbon AI Meetup\n",
    "   - Porto AI & ML\n",
    "   - Coimbra Tech Talks\n",
    "\n",
    "\ud83d\udd17 Eventbrite\n",
    "   - Pesquisa: \"machine learning portugal\"\n",
    "   \n",
    "Eventos anuais:\n",
    "- Web Summit (Lisboa)\n",
    "- Pixels Camp\n",
    "- ICML/NeurIPS watch parties\n",
    "```\n",
    "\n",
    "### Discord/Slack Especializados\n",
    "\n",
    "**MLX Community**\n",
    "```\n",
    "\ud83d\udd17 Apple MLX Discord\n",
    "   discord.gg/mlx-community\n",
    "\n",
    "Canais importantes:\n",
    "#mlx-help\n",
    "#model-releases\n",
    "#fine-tuning\n",
    "#optimization-tips\n",
    "\n",
    "Perguntas frequentes:\n",
    "- Convers\u00e3o de modelos para MLX\n",
    "- Compara\u00e7\u00e3o MLX vs PyTorch\n",
    "- Quantiza\u00e7\u00e3o e optimiza\u00e7\u00e3o\n",
    "```\n",
    "\n",
    "**TinyML & Edge AI**\n",
    "```\n",
    "\ud83d\udd17 TinyML Foundation Slack\n",
    "\ud83d\udd17 Edge AI Discord\n",
    "\n",
    "Foco:\n",
    "- Modelos para dispositivos limitados\n",
    "- Quantiza\u00e7\u00e3o agressiva\n",
    "- Optimiza\u00e7\u00f5es espec\u00edficas\n",
    "\n",
    "Relevante para M1:\n",
    "- T\u00e9cnicas transfer\u00edveis\n",
    "- Benchmarks comparativos\n",
    "```\n",
    "\n",
    "**Hugging Face Discord**\n",
    "```\n",
    "\ud83d\udd17 hf.co/join/discord\n",
    "\n",
    "Canais relevantes:\n",
    "#transformers-help\n",
    "#peft (LoRA/QLoRA)\n",
    "#trl (RLHF)\n",
    "#optimum (optimiza\u00e7\u00e3o)\n",
    "\n",
    "Experts ativos:\n",
    "- Equipa oficial responde r\u00e1pido\n",
    "- Comunidade muito prest\u00e1vel\n",
    "```\n",
    "\n",
    "### Como Pedir Ajuda Eficazmente\n",
    "\n",
    "**Template de Pergunta Boa**\n",
    "```markdown\n",
    "## Contexto\n",
    "MacBook Pro M1 16GB, macOS 14.x\n",
    "Python 3.11 (ARM64)\n",
    "TensorFlow 2.16.1 + Metal 1.1.0\n",
    "\n",
    "## Problema\n",
    "Out of Memory ao treinar EfficientNetB0 com batch_size=32\n",
    "\n",
    "## O que j\u00e1 tentei\n",
    "1. Reduzir batch_size para 16 - mesmo problema\n",
    "2. Mixed precision activado\n",
    "3. Fechar todas as apps\n",
    "\n",
    "## C\u00f3digo m\u00ednimo\n",
    "```python\n",
    "model = tf.keras.applications.EfficientNetB0(...)\n",
    "model.fit(dataset, batch_size=16, epochs=10)\n",
    "# OOM no epoch 2\n",
    "```\n",
    "\n",
    "## Erro completo\n",
    "[paste do erro]\n",
    "\n",
    "## Pergunta espec\u00edfica\n",
    "Que outros par\u00e2metros posso ajustar sem perder \n",
    "demasiada performance?\n",
    "```\n",
    "\n",
    "**O que N\u00c3O fazer:**\n",
    "```\n",
    "\u274c \"n\u00e3o funciona, ajuda?\"\n",
    "\u274c Screenshot de c\u00f3digo (cola texto!)\n",
    "\u274c \"qual \u00e9 o melhor modelo?\"\n",
    "\u274c N\u00e3o dar contexto (vers\u00f5es, sistema)\n",
    "\u274c Fazer m\u00faltiplas perguntas numa s\u00f3 thread\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9.2 Leitura Complementar\n",
    "\n",
    "### Documenta\u00e7\u00e3o Oficial (Priorit\u00e1rio!)\n",
    "\n",
    "**TensorFlow**\n",
    "```\n",
    "\ud83d\udd17 tensorflow.org/guide\n",
    "\ud83d\udd17 tensorflow.org/api_docs\n",
    "\n",
    "Sec\u00e7\u00f5es essenciais:\n",
    "1. Keras Guide - Treino b\u00e1sico\n",
    "2. Performance Guide - Optimiza\u00e7\u00f5es\n",
    "3. Mixed Precision - FP16\n",
    "4. tf.data - Pipeline eficiente\n",
    "\n",
    "Espec\u00edfico M1:\n",
    "\ud83d\udd17 developer.apple.com/metal/tensorflow-plugin/\n",
    "```\n",
    "\n",
    "**PyTorch**\n",
    "```\n",
    "\ud83d\udd17 pytorch.org/docs\n",
    "\ud83d\udd17 pytorch.org/tutorials\n",
    "\n",
    "Essenciais:\n",
    "1. Tensor Basics\n",
    "2. Autograd Mechanics\n",
    "3. torch.utils.data\n",
    "4. torch.nn\n",
    "5. MPS Backend (M1)\n",
    "\n",
    "Tutorial M1:\n",
    "\ud83d\udd17 pytorch.org/docs/stable/notes/mps.html\n",
    "```\n",
    "\n",
    "**MLX (Apple)**\n",
    "```\n",
    "\ud83d\udd17 ml-explore.github.io/mlx/\n",
    "\n",
    "Start here:\n",
    "1. Quick Start\n",
    "2. Unified Memory\n",
    "3. Lazy Evaluation\n",
    "4. Examples Gallery\n",
    "\n",
    "GitHub:\n",
    "\ud83d\udd17 github.com/ml-explore/mlx-examples\n",
    "   - LLM fine-tuning\n",
    "   - Modelos convertidos\n",
    "   - Benchmarks\n",
    "```\n",
    "\n",
    "**Transformers (Hugging Face)**\n",
    "```\n",
    "\ud83d\udd17 huggingface.co/docs/transformers\n",
    "\n",
    "Guias importantes:\n",
    "1. Pipeline Tutorial\n",
    "2. Fine-tuning\n",
    "3. PEFT (LoRA)\n",
    "4. Quantization\n",
    "5. Performance & Optimization\n",
    "\n",
    "Curso gratuito:\n",
    "\ud83d\udd17 huggingface.co/learn/nlp-course\n",
    "```\n",
    "\n",
    "### Papers Fundamentais\n",
    "\n",
    "**Arquitecturas Base**\n",
    "```\n",
    "\ud83d\udcc4 Attention Is All You Need (2017)\n",
    "   Transformer original\n",
    "   \ud83d\udd17 arxiv.org/abs/1706.03762\n",
    "\n",
    "\ud83d\udcc4 BERT (2018)\n",
    "   Bidirectional pre-training\n",
    "   \ud83d\udd17 arxiv.org/abs/1810.04805\n",
    "\n",
    "\ud83d\udcc4 EfficientNet (2019)\n",
    "   Scaling CNNs efficiently\n",
    "   \ud83d\udd17 arxiv.org/abs/1905.11946\n",
    "```\n",
    "\n",
    "**Optimiza\u00e7\u00e3o e Quantiza\u00e7\u00e3o**\n",
    "```\n",
    "\ud83d\udcc4 LoRA: Low-Rank Adaptation (2021)\n",
    "   Fine-tuning eficiente\n",
    "   \ud83d\udd17 arxiv.org/abs/2106.09685\n",
    "\n",
    "\ud83d\udcc4 QLoRA (2023)\n",
    "   Quantized LoRA\n",
    "   \ud83d\udd17 arxiv.org/abs/2305.14314\n",
    "\n",
    "\ud83d\udcc4 Mixed Precision Training (2017)\n",
    "   FP16 training\n",
    "   \ud83d\udd17 arxiv.org/abs/1710.03740\n",
    "```\n",
    "\n",
    "**LLMs Modernos**\n",
    "```\n",
    "\ud83d\udcc4 LLaMA (2023)\n",
    "   Open foundation models\n",
    "   \ud83d\udd17 arxiv.org/abs/2302.13971\n",
    "\n",
    "\ud83d\udcc4 Mistral 7B (2023)\n",
    "   Efficient 7B model\n",
    "   \ud83d\udd17 arxiv.org/abs/2310.06825\n",
    "\n",
    "\ud83d\udcc4 Phi-2 (2023)\n",
    "   Small but capable\n",
    "   \ud83d\udd17 huggingface.co/microsoft/phi-2\n",
    "```\n",
    "\n",
    "### Blogs T\u00e9cnicos Essenciais\n",
    "\n",
    "**Oficiantes de Frameworks**\n",
    "```\n",
    "\ud83d\udd17 tensorflow.org/blog\n",
    "   - Releases\n",
    "   - Tutoriais\n",
    "   - Case studies\n",
    "\n",
    "\ud83d\udd17 pytorch.org/blog\n",
    "   - Novidades\n",
    "   - Performance tips\n",
    "   - Ecosystem updates\n",
    "\n",
    "\ud83d\udd17 huggingface.co/blog\n",
    "   - State of AI\n",
    "   - Model releases\n",
    "   - T\u00e9cnicas novas\n",
    "```\n",
    "\n",
    "**Blogs Independentes (Alta Qualidade)**\n",
    "```\n",
    "\ud83d\udd17 sebastianraschka.com\n",
    "   - ML fundamentals\n",
    "   - PyTorch deep dives\n",
    "   - Paper implementations\n",
    "\n",
    "\ud83d\udd17 karpathy.github.io\n",
    "   - Andrej Karpathy (ex-Tesla AI)\n",
    "   - nanoGPT, tutorials\n",
    "   - Did\u00e1tico e profundo\n",
    "\n",
    "\ud83d\udd17 lilianweng.github.io\n",
    "   - Papers explained\n",
    "   - RL, LLMs\n",
    "   - Muito bem escrito\n",
    "\n",
    "\ud83d\udd17 distill.pub\n",
    "   - Visualiza\u00e7\u00f5es interativas\n",
    "   - Explica\u00e7\u00f5es profundas\n",
    "   - Machine learning interpretability\n",
    "```\n",
    "\n",
    "**Espec\u00edficos para M1/Apple Silicon**\n",
    "```\n",
    "\ud83d\udd17 developer.apple.com/machine-learning/\n",
    "   - ML updates\n",
    "   - Core ML news\n",
    "   - Metal performance\n",
    "\n",
    "\ud83d\udd17 blog.tensorflow.org/search/label/Mac\n",
    "   - TensorFlow no Mac\n",
    "   - Optimiza\u00e7\u00f5es\n",
    "\n",
    "Reddit: r/AppleSilicon\n",
    "   - Benchmarks comunit\u00e1rios\n",
    "   - Tips & tricks\n",
    "```\n",
    "\n",
    "### Newsletters\n",
    "\n",
    "**The Batch (DeepLearning.AI)**\n",
    "```\n",
    "\ud83d\udd17 deeplearning.ai/the-batch\n",
    "\n",
    "Frequ\u00eancia: Semanal\n",
    "Conte\u00fado:\n",
    "- Not\u00edcias de AI\n",
    "- Novos papers explicados\n",
    "- Industry trends\n",
    "- Gr\u00e1tis\n",
    "\n",
    "Por que subscrever:\n",
    "\u2705 Andrew Ng curated\n",
    "\u2705 N\u00e3o-t\u00e9cnico mas informado\n",
    "\u2705 Bom overview do campo\n",
    "```\n",
    "\n",
    "**Papers With Code Newsletter**\n",
    "```\n",
    "\ud83d\udd17 paperswithcode.com/newsletter\n",
    "\n",
    "Frequ\u00eancia: Semanal\n",
    "Conte\u00fado:\n",
    "- Top papers da semana\n",
    "- Benchmarks updates\n",
    "- Code implementations\n",
    "- Datasets novos\n",
    "\n",
    "Por que subscrever:\n",
    "\u2705 Papers + c\u00f3digo\n",
    "\u2705 Benchmarks comparativos\n",
    "\u2705 Muito pr\u00e1tico\n",
    "```\n",
    "\n",
    "**Import AI (Jack Clark)**\n",
    "```\n",
    "\ud83d\udd17 importai.substack.com\n",
    "\n",
    "Frequ\u00eancia: Semanal\n",
    "Conte\u00fado:\n",
    "- Papers importantes\n",
    "- Policy & ethics\n",
    "- Industry news\n",
    "- Gr\u00e1tis\n",
    "\n",
    "Por que subscrever:\n",
    "\u2705 Vis\u00e3o hol\u00edstica\n",
    "\u2705 N\u00e3o s\u00f3 t\u00e9cnico\n",
    "\u2705 Bem escrito\n",
    "```\n",
    "\n",
    "### Cursos Online (Gratuitos)\n",
    "\n",
    "**Fast.ai**\n",
    "```\n",
    "\ud83d\udd17 course.fast.ai\n",
    "\n",
    "Cursos:\n",
    "1. Practical Deep Learning (parte 1 & 2)\n",
    "2. From Deep Learning Foundations to Stable Diffusion\n",
    "\n",
    "Por que fazer:\n",
    "\u2705 Approach pr\u00e1tico (c\u00f3digo primeiro)\n",
    "\u2705 Gratuito e completo\n",
    "\u2705 Funciona bem no M1\n",
    "\u2705 Jeremy Howard \u00e9 excelente professor\n",
    "\n",
    "Tempo: ~40h cada curso\n",
    "```\n",
    "\n",
    "**Stanford CS229 (ML)**\n",
    "```\n",
    "\ud83d\udd17 cs229.stanford.edu\n",
    "\n",
    "Conte\u00fado:\n",
    "- Fundamentos matem\u00e1ticos\n",
    "- Algoritmos cl\u00e1ssicos\n",
    "- Deep learning intro\n",
    "\n",
    "Por que fazer:\n",
    "\u2705 Base te\u00f3rica s\u00f3lida\n",
    "\u2705 Exerc\u00edcios desafiantes\n",
    "\u2705 Gratuito (audit)\n",
    "\n",
    "Pr\u00e9-requisitos: C\u00e1lculo, \u00c1lgebra Linear\n",
    "```\n",
    "\n",
    "**Hugging Face Course**\n",
    "```\n",
    "\ud83d\udd17 huggingface.co/learn\n",
    "\n",
    "Cursos:\n",
    "1. NLP Course\n",
    "2. Deep RL Course\n",
    "3. Audio Course\n",
    "\n",
    "Por que fazer:\n",
    "\u2705 Transformers modernos\n",
    "\u2705 Hands-on com datasets reais\n",
    "\u2705 Certificado gratuito\n",
    "\n",
    "Tempo: 20-30h\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9.3 Actualiza\u00e7\u00f5es e Futuro\n",
    "\n",
    "### M2 / M3 / M4 - O que Mudou?\n",
    "\n",
    "**Compara\u00e7\u00e3o de Hardware**\n",
    "\n",
    "| Chip | RAM M\u00e1x | GPU Cores | Neural Engine | Ideal para |\n",
    "|------|---------|-----------|---------------|------------|\n",
    "| **M1** | 16GB | 8 | 16-core | Modelos \u22647B |\n",
    "| **M1 Pro** | 32GB | 16 | 16-core | Modelos \u226413B |\n",
    "| **M2** | 24GB | 10 | 16-core | Modelos \u22647B |\n",
    "| **M2 Pro** | 32GB | 19 | 16-core | Modelos \u226413B |\n",
    "| **M3** | 24GB | 10 | 16-core | Modelos \u22647B |\n",
    "| **M3 Max** | 128GB | 40 | 16-core | Modelos \u226470B |\n",
    "| **M4** | 32GB | 10 | 16-core | Modelos \u226413B |\n",
    "\n",
    "**Quando vale a upgrade?**\n",
    "```\n",
    "De M1 16GB para:\n",
    "\n",
    "M2/M3 (24GB base):\n",
    "\u2705 Se trabalhas com modelos 7-13B frequentemente\n",
    "\u26a0\ufe0f Ganho moderado (GPU ~20% mais r\u00e1pida)\n",
    "\u274c Caro para o ganho\n",
    "\n",
    "M2/M3 Pro (32GB):\n",
    "\u2705 Se treinas modelos 13B+ regularmente\n",
    "\u2705 M\u00faltiplos modelos em simult\u00e2neo\n",
    "\u2705 Datasets >30GB\n",
    "\ud83d\udcb0 Investimento significativo mas justific\u00e1vel\n",
    "\n",
    "M3 Max (64-128GB):\n",
    "\u2705 Se trabalhas profissionalmente com LLMs\n",
    "\u2705 Fine-tuning de modelos 30B+\n",
    "\u2705 Produ\u00e7\u00e3o de ML\n",
    "\ud83d\udcb0 Muito caro, considera cloud para casos pontuais\n",
    "```\n",
    "\n",
    "**Software j\u00e1 optimizado:**\n",
    "- \u2705 TensorFlow Metal (todas as vers\u00f5es)\n",
    "- \u2705 PyTorch MPS (M1-M4)\n",
    "- \u2705 MLX (nativo, melhor em chips novos)\n",
    "- \u2705 Core ML (optimizado por Apple)\n",
    "\n",
    "### Novas Vers\u00f5es de Frameworks\n",
    "\n",
    "**TensorFlow**\n",
    "```\n",
    "Tend\u00eancia: Menos updates para Mac\n",
    "Recomenda\u00e7\u00e3o actual: 2.16.x + Metal 1.1.x\n",
    "\n",
    "Futuro:\n",
    "- Foco em JAX (sucessor prov\u00e1vel)\n",
    "- Keras 3.0 (multi-backend)\n",
    "- Manuten\u00e7\u00e3o mas sem grandes novidades\n",
    "\n",
    "Quando actualizar:\n",
    "\u2705 Novo modelo suportado que precisas\n",
    "\u26a0\ufe0f Se actual funciona, n\u00e3o mexe\n",
    "\u274c Evita bleeding edge\n",
    "```\n",
    "\n",
    "**PyTorch**\n",
    "```\n",
    "Tend\u00eancia: Suporte MPS cada vez melhor\n",
    "Recomenda\u00e7\u00e3o actual: 2.x (latest stable)\n",
    "\n",
    "Futuro:\n",
    "- torch.compile() melhor no M1\n",
    "- Mais ops suportadas em MPS\n",
    "- Integra\u00e7\u00e3o com Metal 3\n",
    "\n",
    "Quando actualizar:\n",
    "\u2705 A cada 3-4 meses (melhorias significativas)\n",
    "\u2705 Quando precisas de feature espec\u00edfica\n",
    "```\n",
    "\n",
    "**MLX**\n",
    "```\n",
    "Tend\u00eancia: Framework do futuro para Apple\n",
    "Recomenda\u00e7\u00e3o: \u00daltima vers\u00e3o sempre\n",
    "\n",
    "Futuro:\n",
    "- Mais modelos pr\u00e9-convertidos\n",
    "- Tooling melhorado\n",
    "- Poss\u00edvel integra\u00e7\u00e3o oficial Apple\n",
    "\n",
    "Quando usar:\n",
    "\u2705 Projectos novos\n",
    "\u2705 LLMs no Mac\n",
    "\u2705 Quando performance \u00e9 cr\u00edtica\n",
    "```\n",
    "\n",
    "**Transformers (HF)**\n",
    "```\n",
    "Tend\u00eancia: Updates frequentes\n",
    "Recomenda\u00e7\u00e3o: Latest stable\n",
    "\n",
    "Actualiza quando:\n",
    "\u2705 Novo modelo que queres usar\n",
    "\u2705 Fixes de bugs\n",
    "\u2705 Novas features (PEFT, etc.)\n",
    "\n",
    "Cuidado:\n",
    "\u26a0\ufe0f Breaking changes poss\u00edveis\n",
    "\u26a0\ufe0f Testa em ambiente separado primeiro\n",
    "```\n",
    "\n",
    "### Tend\u00eancias em Edge ML\n",
    "\n",
    "**Quantiza\u00e7\u00e3o Extrema**\n",
    "```\n",
    "Direc\u00e7\u00e3o: Modelos cada vez menores\n",
    "\n",
    "T\u00e9cnicas emergentes:\n",
    "- 1-bit LLMs (BitNet)\n",
    "- Ternary quantization\n",
    "- Mixed precision mais agressivo\n",
    "\n",
    "Para M1:\n",
    "\u2705 Permite modelos maiores\n",
    "\u2705 Mais r\u00e1pido\n",
    "\u26a0\ufe0f Trade-off qualidade ainda significativo\n",
    "```\n",
    "\n",
    "**On-Device Training**\n",
    "```\n",
    "Tend\u00eancia: Treino directo no dispositivo\n",
    "\n",
    "Aplica\u00e7\u00f5es:\n",
    "- Personaliza\u00e7\u00e3o de modelos\n",
    "- Federated learning\n",
    "- Privacy-preserving ML\n",
    "\n",
    "No M1:\n",
    "\u2705 LoRA j\u00e1 permite isto\n",
    "\u2705 Tend\u00eancia a facilitar mais\n",
    "\ud83d\udd2e Futuro: One-shot personalization\n",
    "```\n",
    "\n",
    "**Multimodal**\n",
    "```\n",
    "Tend\u00eancia: Modelos que juntam texto/imagem/\u00e1udio\n",
    "\n",
    "Exemplos:\n",
    "- CLIP (texto + imagem)\n",
    "- Whisper (\u00e1udio \u2192 texto)\n",
    "- GPT-4V (vis\u00e3o)\n",
    "\n",
    "No M1:\n",
    "\u2705 CLIP funciona bem\n",
    "\u2705 Whisper optimizado\n",
    "\u26a0\ufe0f Modelos grandes ainda pesados\n",
    "```\n",
    "\n",
    "### Roadmap de Aprendizagem (6-12 meses)\n",
    "\n",
    "**N\u00edvel 1: Consolida\u00e7\u00e3o (Meses 1-3)**\n",
    "```\n",
    "Foco: Dominar o b\u00e1sico profundamente\n",
    "\n",
    "Tarefas:\n",
    "\u25a1 Refazer os 3 projectos do M\u00f3dulo 7 do zero\n",
    "\u25a1 Experimentar com 3 datasets diferentes\n",
    "\u25a1 Contribuir para 1 projecto open source\n",
    "\u25a1 Escrever 3 blog posts sobre aprendizagens\n",
    "\n",
    "Objectivo:\n",
    "- Transfer learning muscle memory\n",
    "- Debugging independente\n",
    "- Workflow profissional\n",
    "```\n",
    "\n",
    "**N\u00edvel 2: Especializa\u00e7\u00e3o (Meses 4-6)**\n",
    "```\n",
    "Escolhe 1 \u00e1rea para especializar:\n",
    "\n",
    "Op\u00e7\u00e3o A - Computer Vision:\n",
    "\u25a1 Object detection (YOLO, Faster R-CNN)\n",
    "\u25a1 Segmentation (U-Net, SAM)\n",
    "\u25a1 GANs e diffusion models\n",
    "\u25a1 Deploy em app iOS com Core ML\n",
    "\n",
    "Op\u00e7\u00e3o B - NLP:\n",
    "\u25a1 Fine-tuning avan\u00e7ado (RLHF)\n",
    "\u25a1 RAG systems\n",
    "\u25a1 Embeddings e vector DBs\n",
    "\u25a1 Agents e tool use\n",
    "\n",
    "Op\u00e7\u00e3o C - LLMs:\n",
    "\u25a1 Treinar desde scratch (modelos pequenos)\n",
    "\u25a1 Quantiza\u00e7\u00e3o avan\u00e7ada\n",
    "\u25a1 Serving optimizado\n",
    "\u25a1 Multi-LoRA systems\n",
    "```\n",
    "\n",
    "**N\u00edvel 3: Produ\u00e7\u00e3o (Meses 7-9)**\n",
    "```\n",
    "Foco: Levar modelos para produ\u00e7\u00e3o\n",
    "\n",
    "Projectos:\n",
    "\u25a1 Deploy modelo como API (FastAPI + Docker)\n",
    "\u25a1 Monitoring e logging\n",
    "\u25a1 A/B testing de modelos\n",
    "\u25a1 CI/CD pipeline\n",
    "\n",
    "Skills:\n",
    "- MLOps basics\n",
    "- Containeriza\u00e7\u00e3o\n",
    "- Cloud deployment\n",
    "- Performance monitoring\n",
    "```\n",
    "\n",
    "**N\u00edvel 4: Contribui\u00e7\u00e3o (Meses 10-12)**\n",
    "```\n",
    "Foco: Dar back \u00e0 comunidade\n",
    "\n",
    "Actividades:\n",
    "\u25a1 Contribuir para framework (MLX, Transformers)\n",
    "\u25a1 Escrever tutorial t\u00e9cnico popular\n",
    "\u25a1 Apresentar em meetup local\n",
    "\u25a1 Mentorizar 1-2 pessoas\n",
    "\n",
    "Objectivo:\n",
    "- Consolidar conhecimento a ensinar\n",
    "- Network profissional\n",
    "- Portfolio p\u00fablico forte\n",
    "```\n",
    "\n",
    "### Recursos Finais\n",
    "\n",
    "**Mant\u00e9m-te Actualizado**\n",
    "```\n",
    "Daily (5-10 min):\n",
    "- Hacker News (AI section)\n",
    "- Reddit r/MachineLearning (hot)\n",
    "\n",
    "Weekly (30-60 min):\n",
    "- 2-3 newsletters\n",
    "- Papers With Code trending\n",
    "- 1 blog post t\u00e9cnico\n",
    "\n",
    "Monthly (2-4h):\n",
    "- Curso online (1 m\u00f3dulo)\n",
    "- Experimentar novo modelo/t\u00e9cnica\n",
    "- Review do que aprendeste\n",
    "```\n",
    "\n",
    "**Network**\n",
    "```\n",
    "Online:\n",
    "- LinkedIn (liga a pessoas do campo)\n",
    "- Twitter/X (segue researchers)\n",
    "- Discord communities (participa)\n",
    "\n",
    "Offline:\n",
    "- Meetups locais\n",
    "- Confer\u00eancias (Web Summit, etc.)\n",
    "- Universidades (talks abertos)\n",
    "```\n",
    "\n",
    "**Pr\u00e1tica Cont\u00ednua**\n",
    "```\n",
    "Regra: 1 projecto novo a cada 2-3 meses\n",
    "\n",
    "Ideias:\n",
    "- Kaggle competition\n",
    "- Contribui\u00e7\u00e3o open source\n",
    "- Dataset pr\u00f3prio\n",
    "- Reimplementar paper\n",
    "- Tool/library \u00fatil\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Conclus\u00e3o do Curso\n",
    "\n",
    "### O que Conquistaste\n",
    "\n",
    "\u2705 **Setup Completo**: M1 optimizado para ML  \n",
    "\u2705 **Fundamentos S\u00f3lidos**: Transfer learning, fine-tuning, optimiza\u00e7\u00e3o  \n",
    "\u2705 **3 Projectos Portfolio**: Imagens, NLP, LLMs  \n",
    "\u2705 **Troubleshooting**: Resolves problemas independentemente  \n",
    "\u2705 **Boas Pr\u00e1ticas**: Workflows profissionais  \n",
    "\u2705 **Comunidade**: Sabes onde pedir ajuda  \n",
    "\n",
    "### Pr\u00f3ximos Passos Recomendados\n",
    "\n",
    "**Imediato (Esta semana):**\n",
    "1. Escolhe 1 projecto pessoal\n",
    "2. Configura reposit\u00f3rio GitHub\n",
    "3. Come\u00e7a com dataset pequeno\n",
    "\n",
    "**Curto prazo (M\u00eas 1):**\n",
    "1. Completa projecto pessoal\n",
    "2. Escreve README detalhado\n",
    "3. Partilha na comunidade\n",
    "\n",
    "**M\u00e9dio prazo (Meses 2-3):**\n",
    "1. Contribui para projecto open source\n",
    "2. Escreve 1 blog post t\u00e9cnico\n",
    "3. Experimenta nova t\u00e9cnica/modelo\n",
    "\n",
    "**Longo prazo (Meses 4-12):**\n",
    "1. Especializa numa \u00e1rea\n",
    "2. Publica portfolio online\n",
    "3. Network activamente\n",
    "4. Considera certifica\u00e7\u00f5es\n",
    "\n",
    "### Palavras Finais\n",
    "\n",
    "> \"O melhor momento para come\u00e7ar foi h\u00e1 um ano. O segundo melhor momento \u00e9 agora.\"\n",
    "\n",
    "Tens agora todas as ferramentas para seres produtivo em ML no M1 16GB. A diferen\u00e7a entre iniciante e profissional est\u00e1 na pr\u00e1tica consistente.\n",
    "\n",
    "**N\u00e3o esperes ser perfeito. Come\u00e7a.**\n",
    "\n",
    "Boa sorte! \ud83d\ude80\n",
    "\n",
    "---\n",
    "\n",
    "**Recursos Quick Links:**\n",
    "- \ud83d\udcda Documenta\u00e7\u00e3o: [Links acima]\n",
    "- \ud83d\udcac Comunidade: [Discords/Forums]\n",
    "- \ud83d\udcf0 News: [Newsletters]\n",
    "- \ud83c\udf93 Cursos: [Fast.ai, HF, Stanford]\n",
    "\n",
    "**Mant\u00e9m contacto:**\n",
    "- GitHub: Faz fork do curso\n",
    "- Comunidades PT: Junta-te aos grupos\n",
    "- Partilha progressos: #100DaysOfML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}