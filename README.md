# Curso Completo: Treinamento de Modelos de Machine Learning em Apple Silicon (M1/M2/M3)

![Apple Silicon](https://img.shields.io/badge/Apple_Silicon-M1%2FM2%2FM3-black?style=for-the-badge&logo=apple)
![Python](https://img.shields.io/badge/Python-3.11%2B-blue?style=for-the-badge&logo=python)
![Frameworks](https://img.shields.io/badge/Frameworks-TensorFlow%20%7C%20PyTorch%20%7C%20MLX-orange?style=for-the-badge)

## üìñ Sobre o Curso

Este reposit√≥rio cont√©m o material completo para o curso "Como Treinar Modelos de Aprendizagem Autom√°tica no MacBook Pro M1". O objetivo √© capacitar desenvolvedores e entusiastas de IA a extrair o m√°ximo de performance da arquitetura Apple Silicon para tarefas de Machine Learning, desde a configura√ß√£o do ambiente at√© o fine-tuning de Large Language Models (LLMs).

O conte√∫do est√° estruturado em m√≥dulos sequenciais, projetados para construir uma base s√≥lida e avan√ßar para t√≥picos complexos de forma gradual.

## üìö T√≥picos Abordados

- **Configura√ß√£o de Ambiente:** Prepara√ß√£o otimizada com Homebrew, Miniforge e ambientes virtuais.
- **Frameworks Acelerados:** Uso de TensorFlow (Metal), PyTorch (MPS) e o novo MLX da Apple.
- **Gest√£o de Mem√≥ria:** Estrat√©gias para trabalhar com a Arquitetura de Mem√≥ria Unificada (UMA) de 16GB.
- **Treinamento de Modelos:** Classifica√ß√£o de imagens (CNNs), NLP (Transformers) e modelos tabulares (Gradient Boosting).
- **Otimiza√ß√£o Avan√ßada:** T√©cnicas de quantiza√ß√£o (PTQ, QAT), pruning e knowledge distillation.
- **Large Language Models (LLMs):** Fine-tuning de modelos de at√© 7B de par√¢metros com LoRA, QLoRA e o framework MLX.
- **Deployment:** Convers√£o de modelos para Core ML e cria√ß√£o de APIs REST e interfaces com Streamlit.
- **Projetos Pr√°ticos:** Tr√™s projetos completos para aplicar todo o conhecimento adquirido.

## üéØ P√∫blico-Alvo

Este curso √© ideal para:
- Desenvolvedores com um MacBook (M1, M2, M3) que desejam entrar na √°rea de IA.
- Estudantes de ci√™ncia de dados que buscam otimizar seus workflows em hardware local.
- Profissionais de ML que querem aproveitar a efici√™ncia energ√©tica e de performance do Apple Silicon.

## ‚úÖ Pr√©-requisitos

- Um MacBook com chip Apple Silicon (M1, M2, M3).
- Conhecimento b√°sico de Python e da linha de comando.
- Familiaridade com conceitos fundamentais de Machine Learning.

---

## üöÄ Estrutura do Curso

### [M√≥dulo 1: Prepara√ß√£o do Ambiente](./modulo_1.md)
- Introdu√ß√£o √† arquitetura Apple Silicon (ARM vs x86, GPU, Neural Engine).
- Configura√ß√£o inicial com Homebrew e Miniforge.
- Instala√ß√£o e teste de frameworks otimizados: TensorFlow-metal, PyTorch-MPS e JAX.

### [M√≥dulo 2: Gest√£o de Recursos e Limita√ß√µes](./modulo_2.md)
- Compreens√£o da Mem√≥ria Unificada (UMA) de 16GB.
- T√©cnicas de monitoramento de mem√≥ria e performance.
- Otimiza√ß√£o de mem√≥ria: Batch Size, Gradient Accumulation, Mixed Precision (FP16).
- Gerenciamento eficiente de datasets (Data Generators e Streaming).

### [M√≥dulo 3: Treino de Modelos Pequenos e M√©dios](./modulo_3.md)
- Classifica√ß√£o de Imagens com CNNs (MobileNet, EfficientNet) e Transfer Learning.
- Processamento de Linguagem Natural (NLP) com modelos compactos (DistilBERT).
- Treinamento de modelos para dados tabulares com XGBoost, LightGBM e CatBoost.

### [M√≥dulo 4: T√©cnicas Avan√ßadas de Otimiza√ß√£o](./modulo_4.md)
- Quantiza√ß√£o de modelos (Post-Training e Quantization-Aware Training).
- Pruning (poda) de redes neurais para compress√£o.
- Knowledge Distillation para transferir conhecimento de modelos grandes para pequenos.
- Estrat√©gias de treino eficiente: Learning Rate Scheduling, Early Stopping e Checkpointing.

### [M√≥dulo 5: Modelos de Linguagem Grandes (LLMs)](./modulo_5.md)
- Estrat√©gias para trabalhar com LLMs em 16GB de RAM.
- Fine-tuning eficiente com LoRA e QLoRA.
- Introdu√ß√£o ao MLX, o framework de ML da Apple.
- Exemplo pr√°tico de fine-tuning de um modelo 7B no M1.

### [M√≥dulo 6: Deployment e Produ√ß√£o](./modulo_6.md)
- Introdu√ß√£o ao Core ML para deployment em dispositivos Apple.
- Convers√£o de modelos Keras e PyTorch para o formato Core ML.
- Monitoramento e debugging com TensorBoard e Weights & Biases (wandb).
- Profiling de performance para identificar gargalos.

### [M√≥dulo 7: Projetos Pr√°ticos](./modulo_7.md)
- **Projeto 1:** Classificador de Imagens (10 classes) com deployment via API REST.
- **Projeto 2:** An√°lise de Sentimentos em portugu√™s com BERT e interface em Streamlit.
- **Projeto 3:** Fine-tuning de um LLM (Mistral 7B) para um dom√≠nio espec√≠fico e cria√ß√£o de um chatbot.

### [M√≥dulo 8: Boas Pr√°ticas e Troubleshooting](./modulo_8.md)
- Workflows eficientes para experimenta√ß√£o e reprodutibilidade.
- Solu√ß√£o de problemas comuns (Out of Memory, lentid√£o, etc.).
- Estrat√©gias para escalar para a nuvem quando necess√°rio.

### [M√≥dulo 9: Recursos Adicionais](./modulo_9.md)
- Links para comunidades, documenta√ß√£o e leitura complementar.
- Discuss√£o sobre o futuro do ML em edge devices.

### [Anexos](./anexos.md)
- Comandos √∫teis, snippets de c√≥digo e checklists de otimiza√ß√£o.

---

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Se voc√™ encontrar um erro, tiver uma sugest√£o de melhoria ou quiser adicionar um novo conte√∫do, sinta-se √† vontade para abrir uma **Issue** ou um **Pull Request**.

## üìÑ Licen√ßa

Este projeto √© distribu√≠do sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
